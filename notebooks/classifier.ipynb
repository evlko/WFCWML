{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388f1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_env import setup_environment\n",
    "\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b18e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38271ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data/history/concat/history_5x5-13k.csv\"\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815a42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 16398\n",
      "Test set size: 5466\n",
      "Validation set size: 5466\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"success\", axis=1).values\n",
    "y = df[\"success\"].values\n",
    "\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_test, y_train_test, test_size=0.25, random_state=42, stratify=y_train_test\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ea8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_classifiers(X_train, y_train, X_test, y_test, X_val, y_val, seed=42):\n",
    "    \"\"\"\n",
    "    Test multiple classification algorithms and compare their performance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=seed),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=seed, n_estimators=100),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "            random_state=seed, n_estimators=100\n",
    "        ),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=seed, n_estimators=100),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=seed, max_iter=1000),\n",
    "        \"SVM (Linear)\": SVC(random_state=seed, probability=True),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing: {name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_test = clf.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "            y_pred_val = clf.predict(X_val)\n",
    "            val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "            cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classifier\": name,\n",
    "                    \"Test Accuracy\": test_accuracy,\n",
    "                    \"Validation Accuracy\": val_accuracy,\n",
    "                    \"CV Mean\": cv_scores.mean(),\n",
    "                    \"CV Std\": cv_scores.std(),\n",
    "                    \"Model\": clf,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "            print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "            print(\n",
    "                f\"5-Fold CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\"\n",
    "            )\n",
    "\n",
    "            print(\"\\nTest Classification Report:\")\n",
    "            print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "            with open(f\"weights/{name.lower().replace(' ', '_')}.pkl\", \"wb\") as file:\n",
    "                pickle.dump(clf, file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {e}\")\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classifier\": name,\n",
    "                    \"Test Accuracy\": 0,\n",
    "                    \"Validation Accuracy\": 0,\n",
    "                    \"CV Mean\": 0,\n",
    "                    \"CV Std\": 0,\n",
    "                    \"Model\": None,\n",
    "                    \"Error\": str(e),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(\"Test Accuracy\", ascending=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7398d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing: Decision Tree\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.9654\n",
      "Validation Accuracy: 0.9629\n",
      "5-Fold CV Accuracy: 0.9648 (+/- 0.0017)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.98      0.97      2733\n",
      "        True       0.98      0.95      0.96      2733\n",
      "\n",
      "    accuracy                           0.97      5466\n",
      "   macro avg       0.97      0.97      0.97      5466\n",
      "weighted avg       0.97      0.97      0.97      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Random Forest\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.9687\n",
      "Validation Accuracy: 0.9689\n",
      "5-Fold CV Accuracy: 0.9673 (+/- 0.0008)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.98      0.97      2733\n",
      "        True       0.98      0.96      0.97      2733\n",
      "\n",
      "    accuracy                           0.97      5466\n",
      "   macro avg       0.97      0.97      0.97      5466\n",
      "weighted avg       0.97      0.97      0.97      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Gradient Boosting\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.9241\n",
      "Validation Accuracy: 0.9263\n",
      "5-Fold CV Accuracy: 0.9249 (+/- 0.0025)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.94      0.93      2733\n",
      "        True       0.94      0.91      0.92      2733\n",
      "\n",
      "    accuracy                           0.92      5466\n",
      "   macro avg       0.92      0.92      0.92      5466\n",
      "weighted avg       0.92      0.92      0.92      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: AdaBoost\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.8401\n",
      "Validation Accuracy: 0.8425\n",
      "5-Fold CV Accuracy: 0.8418 (+/- 0.0027)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.87      0.84      2733\n",
      "        True       0.86      0.81      0.84      2733\n",
      "\n",
      "    accuracy                           0.84      5466\n",
      "   macro avg       0.84      0.84      0.84      5466\n",
      "weighted avg       0.84      0.84      0.84      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Logistic Regression\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.8106\n",
      "Validation Accuracy: 0.8079\n",
      "5-Fold CV Accuracy: 0.8156 (+/- 0.0027)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.84      0.82      2733\n",
      "        True       0.83      0.78      0.81      2733\n",
      "\n",
      "    accuracy                           0.81      5466\n",
      "   macro avg       0.81      0.81      0.81      5466\n",
      "weighted avg       0.81      0.81      0.81      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: SVM (Linear)\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.9469\n",
      "Validation Accuracy: 0.9499\n",
      "5-Fold CV Accuracy: 0.9455 (+/- 0.0040)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.96      0.95      2733\n",
      "        True       0.96      0.93      0.95      2733\n",
      "\n",
      "    accuracy                           0.95      5466\n",
      "   macro avg       0.95      0.95      0.95      5466\n",
      "weighted avg       0.95      0.95      0.95      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: K-Nearest Neighbors\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.9442\n",
      "Validation Accuracy: 0.9426\n",
      "5-Fold CV Accuracy: 0.9449 (+/- 0.0036)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.95      2733\n",
      "        True       0.97      0.92      0.94      2733\n",
      "\n",
      "    accuracy                           0.94      5466\n",
      "   macro avg       0.95      0.94      0.94      5466\n",
      "weighted avg       0.95      0.94      0.94      5466\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Naive Bayes\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.7675\n",
      "Validation Accuracy: 0.7711\n",
      "5-Fold CV Accuracy: 0.7761 (+/- 0.0037)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.87      0.79      2733\n",
      "        True       0.84      0.66      0.74      2733\n",
      "\n",
      "    accuracy                           0.77      5466\n",
      "   macro avg       0.78      0.77      0.76      5466\n",
      "weighted avg       0.78      0.77      0.76      5466\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>CV Mean</th>\n",
       "      <th>CV Std</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.968716</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>0.967252</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.965423</td>\n",
       "      <td>0.962861</td>\n",
       "      <td>0.964813</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.946945</td>\n",
       "      <td>0.949872</td>\n",
       "      <td>0.945481</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>SVC(probability=True, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.944201</td>\n",
       "      <td>0.942554</td>\n",
       "      <td>0.944871</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.924076</td>\n",
       "      <td>0.926271</td>\n",
       "      <td>0.924869</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.840102</td>\n",
       "      <td>0.842481</td>\n",
       "      <td>0.841810</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.810648</td>\n",
       "      <td>0.807903</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.767472</td>\n",
       "      <td>0.771131</td>\n",
       "      <td>0.776132</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Test Accuracy  Validation Accuracy   CV Mean  \\\n",
       "1        Random Forest       0.968716             0.968899  0.967252   \n",
       "0        Decision Tree       0.965423             0.962861  0.964813   \n",
       "5         SVM (Linear)       0.946945             0.949872  0.945481   \n",
       "6  K-Nearest Neighbors       0.944201             0.942554  0.944871   \n",
       "2    Gradient Boosting       0.924076             0.926271  0.924869   \n",
       "3             AdaBoost       0.840102             0.842481  0.841810   \n",
       "4  Logistic Regression       0.810648             0.807903  0.815648   \n",
       "7          Naive Bayes       0.767472             0.771131  0.776132   \n",
       "\n",
       "     CV Std                                              Model  \n",
       "1  0.000829  (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "0  0.001667            DecisionTreeClassifier(random_state=42)  \n",
       "5  0.004048             SVC(probability=True, random_state=42)  \n",
       "6  0.003573                             KNeighborsClassifier()  \n",
       "2  0.002510  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "3  0.002650  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "4  0.002666  LogisticRegression(max_iter=1000, random_state...  \n",
       "7  0.003707                                       GaussianNB()  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_classifiers(X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
