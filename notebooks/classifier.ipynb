{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388f1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_env import setup_environment\n",
    "\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b18e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38271ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'data/history/concat/history_3x3-500.csv'\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "815a42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 338\n",
      "Test set size: 113\n",
      "Validation set size: 113\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('success', axis=1).values\n",
    "y = df['success'].values\n",
    "\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_test, y_train_test, test_size=0.25, random_state=42, stratify=y_train_test\n",
    ")\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n",
    "print(f'Validation set size: {X_val.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ea8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_classifiers(X_train, y_train, X_test, y_test, X_val, y_val, seed=42):\n",
    "    \"\"\"\n",
    "    Test multiple classification algorithms and compare their performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=seed),\n",
    "        'Random Forest': RandomForestClassifier(random_state=seed, n_estimators=100),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=seed, n_estimators=100),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=seed, n_estimators=100),\n",
    "        'Logistic Regression': LogisticRegression(random_state=seed, max_iter=1000),\n",
    "        'SVM (Linear)': SVC(kernel='linear', random_state=seed, probability=True),\n",
    "        'SVM (RBF)': SVC(kernel='rbf', random_state=seed, probability=True),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing: {name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_test = clf.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "            \n",
    "            y_pred_val = clf.predict(X_val)\n",
    "            val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "            cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Test Accuracy': test_accuracy,\n",
    "                'Validation Accuracy': val_accuracy,\n",
    "                'CV Mean': cv_scores.mean(),\n",
    "                'CV Std': cv_scores.std(),\n",
    "                'Model': clf\n",
    "            })\n",
    "\n",
    "            print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "            print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "            print(f\"5-Fold CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "            print(\"\\nTest Classification Report:\")\n",
    "            print(classification_report(y_test, y_pred_test))\n",
    "            \n",
    "            with open(f\"weights/{name.lower().replace(' ', '_')}.pkl\", \"wb\") as file:\n",
    "                pickle.dump(clf, file)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {e}\")\n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Test Accuracy': 0,\n",
    "                'Validation Accuracy': 0,\n",
    "                'CV Mean': 0,\n",
    "                'CV Std': 0,\n",
    "                'Model': None,\n",
    "                'Error': str(e)\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('Test Accuracy', ascending=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7398d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing: Decision Tree\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.4956\n",
      "Validation Accuracy: 0.5310\n",
      "5-Fold CV Accuracy: 0.5710 (+/- 0.0340)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.31      0.39      0.34        38\n",
      "        True       0.64      0.55      0.59        75\n",
      "\n",
      "    accuracy                           0.50       113\n",
      "   macro avg       0.47      0.47      0.47       113\n",
      "weighted avg       0.53      0.50      0.51       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Random Forest\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.6106\n",
      "Validation Accuracy: 0.6726\n",
      "5-Fold CV Accuracy: 0.6154 (+/- 0.0202)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.38      0.26      0.31        38\n",
      "        True       0.68      0.79      0.73        75\n",
      "\n",
      "    accuracy                           0.61       113\n",
      "   macro avg       0.53      0.52      0.52       113\n",
      "weighted avg       0.58      0.61      0.59       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Gradient Boosting\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.6106\n",
      "Validation Accuracy: 0.6726\n",
      "5-Fold CV Accuracy: 0.6480 (+/- 0.0221)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.40      0.32      0.35        38\n",
      "        True       0.69      0.76      0.72        75\n",
      "\n",
      "    accuracy                           0.61       113\n",
      "   macro avg       0.54      0.54      0.54       113\n",
      "weighted avg       0.59      0.61      0.60       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: AdaBoost\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.6549\n",
      "Validation Accuracy: 0.7168\n",
      "5-Fold CV Accuracy: 0.7188 (+/- 0.0540)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.48      0.39      0.43        38\n",
      "        True       0.72      0.79      0.75        75\n",
      "\n",
      "    accuracy                           0.65       113\n",
      "   macro avg       0.60      0.59      0.59       113\n",
      "weighted avg       0.64      0.65      0.65       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Logistic Regression\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.7080\n",
      "Validation Accuracy: 0.6637\n",
      "5-Fold CV Accuracy: 0.6832 (+/- 0.0438)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.29      0.40        38\n",
      "        True       0.72      0.92      0.81        75\n",
      "\n",
      "    accuracy                           0.71       113\n",
      "   macro avg       0.68      0.60      0.60       113\n",
      "weighted avg       0.69      0.71      0.67       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: SVM (Linear)\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.6549\n",
      "Validation Accuracy: 0.6726\n",
      "5-Fold CV Accuracy: 0.6685 (+/- 0.0370)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.46      0.16      0.24        38\n",
      "        True       0.68      0.91      0.78        75\n",
      "\n",
      "    accuracy                           0.65       113\n",
      "   macro avg       0.57      0.53      0.51       113\n",
      "weighted avg       0.61      0.65      0.59       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: SVM (RBF)\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.6903\n",
      "Validation Accuracy: 0.7080\n",
      "5-Fold CV Accuracy: 0.6656 (+/- 0.0207)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.18      0.29        38\n",
      "        True       0.70      0.95      0.80        75\n",
      "\n",
      "    accuracy                           0.69       113\n",
      "   macro avg       0.67      0.57      0.54       113\n",
      "weighted avg       0.68      0.69      0.63       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: K-Nearest Neighbors\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.6726\n",
      "Validation Accuracy: 0.7080\n",
      "5-Fold CV Accuracy: 0.6419 (+/- 0.0387)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.42      0.46        38\n",
      "        True       0.73      0.80      0.76        75\n",
      "\n",
      "    accuracy                           0.67       113\n",
      "   macro avg       0.62      0.61      0.61       113\n",
      "weighted avg       0.66      0.67      0.66       113\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing: Naive Bayes\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.5929\n",
      "Validation Accuracy: 0.6549\n",
      "5-Fold CV Accuracy: 0.6834 (+/- 0.0278)\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.41      0.47      0.44        38\n",
      "        True       0.71      0.65      0.68        75\n",
      "\n",
      "    accuracy                           0.59       113\n",
      "   macro avg       0.56      0.56      0.56       113\n",
      "weighted avg       0.61      0.59      0.60       113\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>CV Mean</th>\n",
       "      <th>CV Std</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>0.683231</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.665628</td>\n",
       "      <td>0.020683</td>\n",
       "      <td>SVC(probability=True, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.641923</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.716814</td>\n",
       "      <td>0.718832</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.668481</td>\n",
       "      <td>0.037032</td>\n",
       "      <td>SVC(kernel='linear', probability=True, random_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.615408</td>\n",
       "      <td>0.020193</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.648025</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.592920</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.683406</td>\n",
       "      <td>0.027769</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.570983</td>\n",
       "      <td>0.034025</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Test Accuracy  Validation Accuracy   CV Mean  \\\n",
       "4  Logistic Regression       0.707965             0.663717  0.683231   \n",
       "6            SVM (RBF)       0.690265             0.707965  0.665628   \n",
       "7  K-Nearest Neighbors       0.672566             0.707965  0.641923   \n",
       "3             AdaBoost       0.654867             0.716814  0.718832   \n",
       "5         SVM (Linear)       0.654867             0.672566  0.668481   \n",
       "1        Random Forest       0.610619             0.672566  0.615408   \n",
       "2    Gradient Boosting       0.610619             0.672566  0.648025   \n",
       "8          Naive Bayes       0.592920             0.654867  0.683406   \n",
       "0        Decision Tree       0.495575             0.530973  0.570983   \n",
       "\n",
       "     CV Std                                              Model  \n",
       "4  0.043778  LogisticRegression(max_iter=1000, random_state...  \n",
       "6  0.020683             SVC(probability=True, random_state=42)  \n",
       "7  0.038742                             KNeighborsClassifier()  \n",
       "3  0.053977  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "5  0.037032  SVC(kernel='linear', probability=True, random_...  \n",
       "1  0.020193  (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "2  0.022132  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "8  0.027769                                       GaussianNB()  \n",
       "0  0.034025            DecisionTreeClassifier(random_state=42)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_classifiers(X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
